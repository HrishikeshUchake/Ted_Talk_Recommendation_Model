{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["import necessary libraries"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import nltk\n", "import string\n", "import warnings\n", "from scipy.stats import pearsonr\n", "from nltk.corpus import stopwords\n", "from wordcloud import WordCloud\n", "from sklearn.feature_extraction.text import TfidfVectorizer\n", "from sklearn.metrics.pairwise import cosine_similarity"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["nltk.download('stopwords')\n", "warnings.filterwarnings('ignore')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Load the dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = pd.read_csv('tedx_dataset.csv')\n", "print(df.head())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Data Preprocessing"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.shape\n", "df.isnull().sum()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["splitted = df['posted'].str.split(' ', expand=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Creating columns for month and year of the talk"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['year'] = splitted[2].astype('int')\n", "df['month'] = splitted[1]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['year'].value_counts().plot.bar()\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Combining the title and the details of the talk."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['details'] = df['title'] + ' ' + df['details']"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Removing the unnecessary information"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = df[['main_speaker', 'details']]\n", "df.dropna(inplace = True)\n", "df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Making a copy of this data for future use."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data = df.copy()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Removing punctuation and stopwords"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def remove_stopwords(text):\n", "  stop_words = stopwords.words('english')\n", "  imp_words = []\n", "  # Storing the important words\n", "  for word in str(text).split():\n", "    word = word.lower()\n", "    if word not in stop_words:\n", "      imp_words.append(word)\n", "  output = \" \".join(imp_words)\n", "  return output"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Applying the function to the details column"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['details'] = df['details'].apply(lambda text: remove_stopwords(text))\n", "df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Removing punctuations"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["punctuations_list = string.punctuation"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Function to remove punctuations from the text"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def cleaning_punctuations(text):\n", "\tsignal = str.maketrans('', '', punctuations_list)\n", "\treturn text.translate(signal)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Applying the function to the details column"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['details'] = df['details'].apply(lambda x: cleaning_punctuations(x))\n", "df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Creating a word cloud to visualize the most common words in the details column"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["details_corpus = \" \".join(df['details'])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(20, 20))\n", "wc = WordCloud(max_words=1000,\n", "\t\t\twidth=800,\n", "\t\t\theight=400).generate(details_corpus)\n", "plt.axis('off')\n", "plt.imshow(wc)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Creating a TF-IDF Vectorizer"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["vectorizer = TfidfVectorizer(analyzer = 'word')\n", "vectorizer.fit(df['details'])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Function to get similarities for a given talk content"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_similarities(talk_content, data=df):\n", "\t# Getting vector for the input talk_content.\n", "\ttalk_array1 = vectorizer.transform(talk_content).toarray()\n", "\t# We will store similarity for each row of the dataset.\n", "\tsim = []\n", "\tpea = []\n", "\tfor idx, row in data.iterrows():\n", "\t\tdetails = row['details']\n", "\t\t# Getting vector for current talk.\n", "\t\ttalk_array2 = vectorizer.transform(\n", "\t\t\tdata[data['details'] == details]['details']).toarray()\n", "\t\t# Calculating cosine similarities\n", "\t\tcos_sim = cosine_similarity(talk_array1, talk_array2)[0][0]\n", "\t\t# Calculating pearson correlation\n", "\t\tpea_sim = pearsonr(talk_array1.squeeze(), talk_array2.squeeze())[0]\n", "\t\tsim.append(cos_sim)\n", "\t\tpea.append(pea_sim)\n", "\treturn sim, pea"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Function to get the top similar/recommended talks"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def recommend_talks(talk_content, data=data):\n", "    data['cos_sim'], data['pea_sim'] = get_similarities(talk_content)\n", "    data.sort_values(by=['cos_sim', 'pea_sim'], ascending=[False, False], inplace=True)\n", "    return data[['main_speaker', 'details']].head(5).to_dict(orient='records')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Example usage"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["talk_content = ['Time Management and working\\\n", "hard to become successful in life']"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["recommend_talks(talk_content)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}